"""
Agente de IA para classifica√ß√£o de urg√™ncia de ocorr√™ncias de emerg√™ncia 911.
Utiliza LangChain, OpenAI e RAG para classificar e direcionar emerg√™ncias.
"""

import os
import json
from typing import Dict, Any, Optional
from dataclasses import dataclass
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.schema import BaseOutputParser
from langchain.schema.output_parser import OutputParserException
from pydantic import BaseModel, Field
from .rag_service import RAGService

@dataclass
class EmergencyClassification:
    """Estrutura para resultado da classifica√ß√£o de emerg√™ncia."""
    canal: str
    nivel_urgencia: int
    justificativa: str
    acoes_recomendadas: list
    tempo_resposta_estimado: str
    confidence_score: float

class EmergencyOutputParser(BaseOutputParser[EmergencyClassification]):
    """Parser personalizado para sa√≠da estruturada do LLM."""
    
    def parse(self, text: str) -> EmergencyClassification:
        """
        Parseia a resposta do LLM para EmergencyClassification.
        
        Args:
            text: Resposta do LLM em formato JSON
            
        Returns:
            EmergencyClassification: Objeto estruturado com a classifica√ß√£o
        """
        try:
            # Tenta extrair JSON da resposta
            start_idx = text.find('{')
            end_idx = text.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise OutputParserException("JSON n√£o encontrado na resposta")
            
            json_str = text[start_idx:end_idx]
            data = json.loads(json_str)
            
            # Valida campos obrigat√≥rios
            required_fields = ["canal", "nivel_urgencia", "justificativa", "acoes_recomendadas", "tempo_resposta_estimado"]
            for field in required_fields:
                if field not in data:
                    raise OutputParserException(f"Campo obrigat√≥rio '{field}' n√£o encontrado")
            
            return EmergencyClassification(
                canal=data["canal"],
                nivel_urgencia=int(data["nivel_urgencia"]),
                justificativa=data["justificativa"],
                acoes_recomendadas=data.get("acoes_recomendadas", []),
                tempo_resposta_estimado=data["tempo_resposta_estimado"],
                confidence_score=float(data.get("confidence_score", 0.8))
            )
            
        except json.JSONDecodeError as e:
            raise OutputParserException(f"Erro ao parsear JSON: {e}")
        except Exception as e:
            raise OutputParserException(f"Erro no parse: {e}")
    
    def get_format_instructions(self) -> str:
        """Retorna instru√ß√µes de formata√ß√£o para o LLM."""
        return """
IMPORTANTE: Responda APENAS com um JSON v√°lido no seguinte formato:

{
    "canal": "bombeiros" | "saude" | "policia" | "defesa_civil" | "transito",
    "nivel_urgencia": 1-5 (1=m√≠nima, 2=baixa, 3=m√©dia, 4=alta, 5=cr√≠tica),
    "justificativa": "Explica√ß√£o detalhada da classifica√ß√£o",
    "acoes_recomendadas": ["a√ß√£o1", "a√ß√£o2", "a√ß√£o3"],
    "tempo_resposta_estimado": "tempo estimado para atendimento",
    "confidence_score": 0.0-1.0
}

N√ÉO inclua texto adicional fora do JSON.
"""

class UrgencyClassifier:
    """Agente principal para classifica√ß√£o de urg√™ncia de emerg√™ncias."""
    
    def __init__(self, openai_api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        """
        Inicializa o classificador de urg√™ncia.
        
        Args:
            openai_api_key: Chave da API OpenAI
            model: Modelo OpenAI a ser usado
        """
        # Configura API key
        if openai_api_key:
            os.environ["OPENAI_API_KEY"] = openai_api_key
        
        # Inicializa LLM
        self.llm = ChatOpenAI(
            model=model,
            temperature=0.1,  # Baixa criatividade para consist√™ncia
            max_tokens=1000
        )
        
        # Inicializa servi√ßo RAG
        self.rag_service = RAGService(openai_api_key)
        
        # Inicializa parser de sa√≠da
        self.output_parser = EmergencyOutputParser()
        
        # Cria prompt template
        self._create_prompt_template()
        
        # Popula base de conhecimento se estiver vazia
        self._ensure_knowledge_base()
    
    def _create_prompt_template(self) -> None:
        """Cria o template de prompt para classifica√ß√£o."""
        
        system_message = SystemMessagePromptTemplate.from_template("""
Voc√™ √© um agente especialista em classifica√ß√£o de emerg√™ncias para o sistema 911.
Sua fun√ß√£o √© analisar relatos de ocorr√™ncias e determinar:
1. Canal apropriado (bombeiros, sa√∫de, pol√≠cia, defesa_civil, transito)
2. N√≠vel de urg√™ncia (1-5)
3. A√ß√µes recomendadas
4. Tempo de resposta estimado

DIRETRIZES DE CLASSIFICA√á√ÉO:

CANAIS:
- bombeiros: inc√™ndios, explos√µes, vazamentos de g√°s, resgates, acidentes com materiais perigosos
- sa√∫de: emerg√™ncias m√©dicas, ferimentos, doen√ßas, overdoses, problemas respirat√≥rios
- policia: crimes, viol√™ncia, dist√∫rbios, acidentes com aspectos criminais
- defesa_civil: desastres naturais, alagamentos, deslizamentos
- transito: acidentes de tr√¢nsito simples, congestionamentos, sinaliza√ß√£o

N√çVEIS DE URG√äNCIA:
- 5 (CR√çTICA): Risco iminente de morte, grandes inc√™ndios, crimes violentos em andamento
- 4 (ALTA): Ferimentos graves, inc√™ndios menores, crimes sem viol√™ncia iminente
- 3 (M√âDIA): Ferimentos moderados, situa√ß√µes de risco controlado
- 2 (BAIXA): Problemas menores, orienta√ß√µes
- 1 (M√çNIMA): Informa√ß√µes, preven√ß√£o

TEMPOS DE RESPOSTA T√çPICOS:
- Cr√≠tica: "Imediato (0-4 minutos)"
- Alta: "Urgente (5-10 minutos)"
- M√©dia: "Moderado (11-20 minutos)"
- Baixa: "Normal (21-60 minutos)"
- M√≠nima: "Quando poss√≠vel (1+ horas)"

{context}

{format_instructions}
""")
        
        human_message = HumanMessagePromptTemplate.from_template("""
RELATO DA OCORR√äNCIA:
{ocorrencia}

Analise este relato e forne√ßa a classifica√ß√£o estruturada conforme as diretrizes.
""")
        
        self.prompt_template = ChatPromptTemplate.from_messages([
            system_message,
            human_message
        ])
    
    def _ensure_knowledge_base(self) -> None:
        """Garante que a base de conhecimento esteja populada."""
        try:
            stats = self.rag_service.get_stats()
            if stats.get("total_documents", 0) == 0:
                print("üìö Populando base de conhecimento inicial...")
                self.rag_service.populate_initial_knowledge_base()
        except Exception as e:
            print(f"‚ö†Ô∏è Aviso: Erro ao verificar base de conhecimento: {e}")
    
    def classify_emergency(self, relato_ocorrencia: str) -> EmergencyClassification:
        """
        Classifica uma ocorr√™ncia de emerg√™ncia.
        
        Args:
            relato_ocorrencia: Descri√ß√£o da ocorr√™ncia
            
        Returns:
            EmergencyClassification: Resultado estruturado da classifica√ß√£o
        """
        try:
            # Busca contexto relevante via RAG
            enhanced_context = self.rag_service.get_enhanced_context(relato_ocorrencia)
            
            # Prepara prompt
            formatted_prompt = self.prompt_template.format_messages(
                context=enhanced_context,
                ocorrencia=relato_ocorrencia,
                format_instructions=self.output_parser.get_format_instructions()
            )
            
            # Gera resposta
            response = self.llm.invoke(formatted_prompt)
            
            # Parseia resposta
            classification = self.output_parser.parse(response.content)
            
            print("‚úÖ Classifica√ß√£o realizada com sucesso!")
            return classification
            
        except Exception as e:
            print(f"‚ùå Erro na classifica√ß√£o: {e}")
            # Retorna classifica√ß√£o de fallback
            return EmergencyClassification(
                canal="saude",  # Canal seguro por padr√£o
                nivel_urgencia=4,  # Alta urg√™ncia por seguran√ßa
                justificativa=f"Erro na classifica√ß√£o autom√°tica: {e}. Direcionado para avalia√ß√£o manual urgente.",
                acoes_recomendadas=["Avalia√ß√£o manual imediata", "Contato direto com operador"],
                tempo_resposta_estimado="Imediato (avalia√ß√£o manual)",
                confidence_score=0.1
            )
    
    def classify_batch(self, relatos: list) -> list:
        """
        Classifica m√∫ltiplas ocorr√™ncias em lote.
        
        Args:
            relatos: Lista de descri√ß√µes de ocorr√™ncias
            
        Returns:
            list: Lista de EmergencyClassification
        """
        results = []
        for i, relato in enumerate(relatos):
            print(f"Processando ocorr√™ncia {i+1}/{len(relatos)}...")
            result = self.classify_emergency(relato)
            results.append(result)
        
        return results
    
    def get_classification_summary(self, classification: EmergencyClassification) -> str:
        """
        Gera resumo textual da classifica√ß√£o.
        
        Args:
            classification: Resultado da classifica√ß√£o
            
        Returns:
            str: Resumo formatado
        """
        urgency_labels = {
            1: "M√çNIMA",
            2: "BAIXA", 
            3: "M√âDIA",
            4: "ALTA",
            5: "CR√çTICA"
        }
        
        summary = f"""
üö® CLASSIFICA√á√ÉO DE EMERG√äNCIA üö®

üìç CANAL: {classification.canal.upper()}
üî• URG√äNCIA: {urgency_labels[classification.nivel_urgencia]} (N√≠vel {classification.nivel_urgencia})
‚è∞ TEMPO RESPOSTA: {classification.tempo_resposta_estimado}
üéØ CONFIAN√áA: {classification.confidence_score:.1%}

üìã JUSTIFICATIVA:
{classification.justificativa}

‚úÖ A√á√ïES RECOMENDADAS:
{chr(10).join(f"‚Ä¢ {acao}" for acao in classification.acoes_recomendadas)}
"""
        return summary.strip()
    
    def add_knowledge(self, documents: list, categories: list = None) -> bool:
        """
        Adiciona conhecimento personalizado √† base.
        
        Args:
            documents: Lista de documentos/textos
            categories: Lista de categorias correspondentes
            
        Returns:
            bool: True se adicionado com sucesso
        """
        metadatas = []
        if categories:
            metadatas = [{"category": cat, "custom": True} for cat in categories]
        
        return self.rag_service.add_documents_to_knowledge_base(documents, metadatas)
    
    def get_system_status(self) -> Dict[str, Any]:
        """
        Retorna status do sistema classificador.
        
        Returns:
            Dict: Status completo do sistema
        """
        return {
            "llm_model": self.llm.model_name,
            "rag_stats": self.rag_service.get_stats(),
            "vector_db_connection": self.rag_service.db_config.test_connection(),
            "system_ready": True
        }

def test_classifier():
    """Fun√ß√£o de teste para o classificador."""
    # Exemplos de teste
    test_cases = [
        "Tem fogo na casa do vizinho, muita fuma√ßa!",
        "Meu pai teve um infarto, n√£o est√° respirando bem",
        "Tem um homem armado na pra√ßa amea√ßando as pessoas",
        "Batida de carro na esquina, um ferido consciente",
        "Vazamento de g√°s no pr√©dio, cheiro forte"
    ]
    
    print("üß™ Iniciando testes do classificador...")
    
    try:
        classifier = UrgencyClassifier()
        
        for i, case in enumerate(test_cases, 1):
            print(f"\n--- TESTE {i} ---")
            print(f"Relato: {case}")
            
            result = classifier.classify_emergency(case)
            print(classifier.get_classification_summary(result))
            
    except Exception as e:
        print(f"‚ùå Erro nos testes: {e}")

if __name__ == "__main__":
    test_classifier()
