"""
Servi√ßo RAG (Retrieval-Augmented Generation) para sistema de emerg√™ncia 911.
Fornece fun√ß√µes utilit√°rias para busca de contexto e gest√£o de conhecimento.
"""

import os
import pandas as pd
import PyPDF2
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain.schema import Document

# Import do FAISS para vector store
from langchain_community.vectorstores import FAISS

# Importa√ß√£o robusta que funciona tanto em execu√ß√£o direta quanto como m√≥dulo
try:
    from .vectordb_config import VectorDBConfig
except ImportError:
    from vectordb_config import VectorDBConfig

class RAGService:
    """Servi√ßo para opera√ß√µes de RAG (Retrieval-Augmented Generation)."""
    
    def __init__(self, openai_api_key: Optional[str] = None):
        """
        Inicializa o servi√ßo RAG.
        
        Args:
            openai_api_key: Chave da API OpenAI (opcional, pode vir de vari√°vel de ambiente)
        """
        self.db_config = VectorDBConfig()
        
        # Configura API key da OpenAI
        if openai_api_key:
            os.environ["OPENAI_API_KEY"] = openai_api_key
        
        # Inicializa embeddings
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            chunk_size=1000
        )
        
        # Inicializa text splitter
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        self.vector_store = None
        self._initialize_vector_store()
    
    def _initialize_vector_store(self) -> None:
        """Inicializa o vector store."""
        try:
            self.vector_store = self.db_config.get_vector_store(self.embeddings)
            print("üîó Vector store FAISS inicializado")
        except Exception as e:
            print(f"‚ùå Erro ao inicializar vector store: {e}")
            raise
    
    def add_documents_to_knowledge_base(self, documents: List[str], metadatas: Optional[List[Dict]] = None) -> bool:
        """
        Adiciona documentos √† base de conhecimento.
        
        Args:
            documents: Lista de textos a serem adicionados
            metadatas: Lista de metadados associados aos documentos
            
        Returns:
            bool: True se documentos foram adicionados com sucesso
        """
        try:
            if not documents:
                print("‚ùå Nenhum documento fornecido.")
                return False
            
            # Processa documentos
            doc_objects = []
            for i, doc_text in enumerate(documents):
                metadata = metadatas[i] if metadatas and i < len(metadatas) else {}
                metadata.update({"source": f"document_{i}", "doc_id": i})
                
                # Divide documento em chunks
                chunks = self.text_splitter.split_text(doc_text)
                
                for j, chunk in enumerate(chunks):
                    chunk_metadata = metadata.copy()
                    chunk_metadata.update({"chunk_id": j, "chunk_index": f"{i}_{j}"})
                    
                    doc_objects.append(Document(
                        page_content=chunk,
                        metadata=chunk_metadata
                    ))
            
            # Adiciona ao vector store
            if self.vector_store:
                self.vector_store.add_documents(doc_objects)
                # Salva o √≠ndice FAISS ap√≥s adicionar documentos
                self.db_config.save_vector_store(self.vector_store)
                print(f"üìù {len(doc_objects)} chunks adicionados e salvos")
                return True
            else:
                print("‚ùå Vector store n√£o inicializado.")
                return False
                
        except Exception as e:
            print(f"‚ùå Erro ao adicionar documentos: {e}")
            return False
    
    def search_relevant_context(self, query: str, top_k: int = 5, score_threshold: float = 1.5) -> List[Dict[str, Any]]:
        """
        Busca contexto relevante na base de conhecimento.
        
        Args:
            query: Consulta de busca
            top_k: N√∫mero m√°ximo de resultados
            score_threshold: Threshold m√°ximo de dist√¢ncia (valores menores = mais similar)
            
        Returns:
            List[Dict]: Lista de contextos relevantes com metadados
        """
        try:
            if not self.vector_store:
                print("‚ùå Vector store n√£o inicializado.")
                return []
            
            # Busca por similaridade com scores
            results = self.vector_store.similarity_search_with_score(
                query=query,
                k=top_k
            )
            
            # DEBUG: Mostra os scores retornados
            # print(f"üîç DEBUG - Scores brutos do Chroma para '{query}':")
            # for i, (doc, score) in enumerate(results):
            #     print(f"   {i+1}. Score: {score:.4f} | Conte√∫do: {doc.page_content[:50]}...")
            
            # Filtra por threshold e formata resultados
            relevant_contexts = []
            for doc, score in results:
                # Chroma usa dist√¢ncia (menor = mais similar)
                # Aceita scores menores que o threshold
                if score <= score_threshold:
                    relevant_contexts.append({
                        "content": doc.page_content,
                        "metadata": doc.metadata,
                        "similarity_score": max(0, 1 - (score / 2))  # Normaliza para 0-1
                    })
            
            print(f"üìö {len(relevant_contexts)} contextos relevantes")
            return relevant_contexts
            
        except Exception as e:
            print(f"‚ùå Erro na busca de contexto: {e}")
            return []
    
    def get_enhanced_context(self, query: str, max_context_length: int = 2000) -> str:
        """
        Busca e formata contexto para melhorar resposta do LLM.
        
        Args:
            query: Consulta original
            max_context_length: Tamanho m√°ximo do contexto em caracteres
            
        Returns:
            str: Contexto formatado para o prompt
        """
        try:
            # Busca contextos relevantes
            contexts = self.search_relevant_context(query, top_k=10)
            
            if not contexts:
                return "Nenhum contexto espec√≠fico encontrado na base de conhecimento."
            
            # Formata contexto
            formatted_context = "CONTEXTO RELEVANTE DA BASE DE CONHECIMENTO:\n\n"
            current_length = len(formatted_context)
            
            for i, ctx in enumerate(contexts, 1):
                context_piece = f"{i}. {ctx['content']}\n"
                
                if current_length + len(context_piece) > max_context_length:
                    break
                
                formatted_context += context_piece
                current_length += len(context_piece)
            
            return formatted_context.strip()
            
        except Exception as e:
            print(f"‚ùå Erro ao obter contexto: {e}")
            return "Erro ao acessar base de conhecimento."
    
    def populate_initial_knowledge_base(self) -> bool:
        """
        Popula a base de conhecimento com dados iniciais sobre emerg√™ncias.
        
        Returns:
            bool: True se popula√ß√£o foi bem-sucedida
        """
        initial_documents = [
            # Conhecimento sobre bombeiros
            """
            PROTOCOLO BOMBEIROS - N√çVEIS DE URG√äNCIA:
            
            URG√äNCIA CR√çTICA (N√≠vel 5):
            - Inc√™ndios em edif√≠cios residenciais ou comerciais
            - Explos√µes com v√≠timas
            - Vazamentos de g√°s com risco de explos√£o
            - Desabamentos com pessoas presas
            - Acidentes com materiais perigosos
            
            URG√äNCIA ALTA (N√≠vel 4):
            - Inc√™ndios em vegeta√ß√£o pr√≥xima a resid√™ncias
            - Vazamentos qu√≠micos sem v√≠timas
            - Acidentes de tr√¢nsito com v√≠timas presas
            
            URG√äNCIA M√âDIA (N√≠vel 3):
            - Inc√™ndios em √°reas n√£o habitadas
            - Animais em situa√ß√£o de risco
            - Quedas de √°rvores obstruindo vias
            
            URG√äNCIA BAIXA (N√≠vel 2):
            - Vazamentos menores de √°gua
            - Remo√ß√£o de galhos
            
            URG√äNCIA M√çNIMA (N√≠vel 1):
            - Informa√ß√µes gerais
            - Orienta√ß√µes preventivas
            """,
            
            # Conhecimento sobre sa√∫de/SAMU
            """
            PROTOCOLO SA√öDE/SAMU - N√çVEIS DE URG√äNCIA:
            
            URG√äNCIA CR√çTICA (N√≠vel 5):
            - Parada cardiorrespirat√≥ria
            - Traumatismo craniano grave
            - Hemorragias arteriais
            - Choque anafil√°tico
            - Queimaduras extensas
            - Overdose/intoxica√ß√£o grave
            
            URG√äNCIA ALTA (N√≠vel 4):
            - Dificuldade respirat√≥ria severa
            - Dor tor√°cica intensa
            - Traumas com fraturas expostas
            - Convuls√µes cont√≠nuas
            - Desmaios com sinais de gravidade
            
            URG√äNCIA M√âDIA (N√≠vel 3):
            - Fraturas simples
            - Cortes profundos
            - Febre alta em crian√ßas
            - Dores abdominais intensas
            
            URG√äNCIA BAIXA (N√≠vel 2):
            - Mal-estar geral
            - Dores moderadas
            - Ferimentos superficiais
            
            URG√äNCIA M√çNIMA (N√≠vel 1):
            - Orienta√ß√µes m√©dicas
            - Informa√ß√µes sobre sintomas leves
            """,
            
            # Conhecimento sobre pol√≠cia
            """
            PROTOCOLO POL√çCIA - N√çVEIS DE URG√äNCIA:
            
            URG√äNCIA CR√çTICA (N√≠vel 5):
            - Homic√≠dios em andamento
            - Sequestros/c√°rcere privado
            - Roubos √† m√£o armada em andamento
            - Tiroteios
            - Amea√ßas de bomba
            - Viol√™ncia dom√©stica com arma
            
            URG√äNCIA ALTA (N√≠vel 4):
            - Furtos em flagrante
            - Brigas com agress√£o f√≠sica
            - Acidentes de tr√¢nsito com feridos
            - Amea√ßas verbais graves
            - Perturba√ß√£o do sossego com viol√™ncia
            
            URG√äNCIA M√âDIA (N√≠vel 3):
            - Furtos consumados
            - Acidentes de tr√¢nsito sem feridos
            - Perturba√ß√£o do sossego
            - Conflitos familiares
            
            URG√äNCIA BAIXA (N√≠vel 2):
            - Boletins de ocorr√™ncia
            - Documentos perdidos
            - Orienta√ß√µes legais
            
            URG√äNCIA M√çNIMA (N√≠vel 1):
            - Informa√ß√µes gerais
            - Den√∫ncias n√£o urgentes
            """,
            
            # Palavras-chave para classifica√ß√£o
            """
            PALAVRAS-CHAVE PARA CLASSIFICA√á√ÉO DE EMERG√äNCIAS:
            
            INDICADORES DE ALTA URG√äNCIA:
            - "n√£o respira", "parou de respirar", "sem pulso"
            - "sangramento", "muito sangue", "hemorragia"
            - "inconsciente", "desmaiou", "n√£o acorda"
            - "fogo", "inc√™ndio", "fuma√ßa", "chamas"
            - "explos√£o", "explodiu", "bomba"
            - "arma", "tiro", "disparo", "baleado"
            - "preso", "soterrado", "n√£o consegue sair"
            
            INDICADORES DE URG√äNCIA M√âDIA:
            - "dor forte", "dor intensa", "n√£o aguenta"
            - "acidente", "bateu", "colis√£o"
            - "quebrou", "fraturou", "machucou"
            - "caiu", "trope√ßou", "escorregou"
            
            CANAIS ESPEC√çFICOS:
            - Termos relacionados a fogo/explos√£o ‚Üí Bombeiros
            - Termos relacionados a sa√∫de/ferimentos ‚Üí SAMU
            - Termos relacionados a crimes/viol√™ncia ‚Üí Pol√≠cia
            """
        ]
        
        metadatas = [
            {"category": "bombeiros", "protocol_type": "urgency_levels"},
            {"category": "saude", "protocol_type": "urgency_levels"},
            {"category": "policia", "protocol_type": "urgency_levels"},
            {"category": "keywords", "protocol_type": "classification_indicators"}
        ]
        
        return self.add_documents_to_knowledge_base(initial_documents, metadatas)
    
    def load_database_files_to_knowledge_base(self) -> bool:
        """
        Carrega todos os arquivos das pastas database/Bombeiros, database/Policia e database/Saude
        para a base de conhecimento vetorial.
        
        Returns:
            bool: True se carregamento foi bem-sucedido
        """
        try:
            # Obt√©m o diret√≥rio base do projeto
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(current_dir)  # Sobe um n√≠vel para sair da pasta agentes
            
            # Diret√≥rios a serem processados
            database_dirs = {
                "bombeiros": os.path.join(project_root, "database", "Bombeiros"),
                "policia": os.path.join(project_root, "database", "Policia"), 
                "saude": os.path.join(project_root, "database", "Saude")
            }
            
            total_files_processed = 0
            total_chunks_added = 0
            
            for category, dir_path in database_dirs.items():
                print(f"üìÅ Processando arquivos da categoria: {category.upper()}")
                
                # Verifica se diret√≥rio existe
                if not os.path.exists(dir_path):
                    print(f"‚ö†Ô∏è  Diret√≥rio n√£o encontrado: {dir_path}")
                    continue
                
                # Percorre todos os arquivos do diret√≥rio
                for file_path in Path(dir_path).rglob("*"):
                    if file_path.is_file():
                        try:
                            file_extension = file_path.suffix.lower()
                            file_name = file_path.name
                            
                            print(f"üìÑ Processando arquivo: {file_name}")
                            
                            # Extrai conte√∫do baseado na extens√£o
                            content = ""
                            if file_extension == ".pdf":
                                content = self._extract_pdf_content(str(file_path))
                            elif file_extension == ".csv":
                                content = self._extract_csv_content(str(file_path))
                            elif file_extension == ".xlsx":
                                content = self._extract_xlsx_content(str(file_path))
                            elif file_extension == ".txt":
                                content = self._extract_txt_content(str(file_path))
                            else:
                                print(f"‚ö†Ô∏è  Tipo de arquivo n√£o suportado: {file_extension}")
                                continue
                            
                            if content:
                                # Prepara metadados
                                metadata = {
                                    "category": category,
                                    "filename": file_name,
                                    "file_path": str(file_path),
                                    "file_type": file_extension,
                                    "source": f"{category}_{file_name}"
                                }
                                
                                # Adiciona √† base de conhecimento
                                if self.add_documents_to_knowledge_base([content], [metadata]):
                                    total_files_processed += 1
                                    # Estima chunks (aproximado)
                                    estimated_chunks = len(content) // 1000
                                    total_chunks_added += estimated_chunks
                                    print(f"‚úÖ Arquivo processado com sucesso!")
                                else:
                                    print(f"‚ùå Falha ao processar arquivo: {file_name}")
                            else:
                                print(f"‚ö†Ô∏è  Conte√∫do vazio ou erro na extra√ß√£o: {file_name}")
                                
                        except Exception as e:
                            print(f"‚ùå Erro ao processar arquivo {file_path}: {e}")
                            continue
            
            print(f"\nüìä RESUMO DO CARREGAMENTO:")
            print(f"   - Arquivos processados: {total_files_processed}")
            print(f"   - Chunks estimados: {total_chunks_added}")
            print(f"   - Status: {'‚úÖ Sucesso' if total_files_processed > 0 else '‚ùå Nenhum arquivo processado'}")
            
            return total_files_processed > 0
            
        except Exception as e:
            print(f"‚ùå Erro geral no carregamento da base: {e}")
            return False
    
    def _extract_pdf_content(self, pdf_path: str) -> str:
        """
        Extrai conte√∫do de texto de um arquivo PDF.
        
        Args:
            pdf_path: Caminho para o arquivo PDF
            
        Returns:
            str: Conte√∫do extra√≠do do PDF
        """
        try:
            content = ""
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                
                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    content += page.extract_text() + "\n"
            
            return content.strip()
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair PDF {pdf_path}: {e}")
            return ""
    
    def _extract_csv_content(self, csv_path: str) -> str:
        """
        Extrai conte√∫do de um arquivo CSV e converte para texto estruturado.
        
        Args:
            csv_path: Caminho para o arquivo CSV
            
        Returns:
            str: Conte√∫do estruturado do CSV
        """
        try:
            # Tenta m√∫ltiplas codifica√ß√µes para CSVs brasileiros
            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'windows-1252']
            
            df = None
            used_encoding = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_path, encoding=encoding)
                    used_encoding = encoding
                    break
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    if "codec" not in str(e).lower():
                        print(f"‚ùå Erro n√£o relacionado √† codifica√ß√£o no CSV {csv_path}: {e}")
                        continue
            
            if df is None:
                print(f"‚ö†Ô∏è  N√£o foi poss√≠vel decodificar o CSV {csv_path} com nenhuma codifica√ß√£o")
                return ""
            
            # Converte para texto estruturado
            content = f"DADOS DO ARQUIVO: {os.path.basename(csv_path)}\n"
            content += f"CODIFICA√á√ÉO USADA: {used_encoding}\n\n"
            
            # Adiciona informa√ß√µes sobre colunas
            content += f"COLUNAS: {', '.join(df.columns.tolist())}\n\n"
            
            # Adiciona algumas estat√≠sticas b√°sicas
            content += f"TOTAL DE REGISTROS: {len(df)}\n\n"
            
            # Adiciona dados (limitando para n√£o ficar muito grande)
            content += "DADOS:\n"
            for index, row in df.head(100).iterrows():  # Limita a 100 linhas
                row_text = " | ".join([f"{col}: {val}" for col, val in row.items() if pd.notna(val)])
                content += f"{row_text}\n"
            
            if len(df) > 100:
                content += f"\n... (exibindo apenas primeiras 100 linhas de {len(df)} registros)"
            
            return content
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair CSV {csv_path}: {e}")
            return ""
    
    def _extract_xlsx_content(self, xlsx_path: str) -> str:
        """
        Extrai conte√∫do de um arquivo XLSX e converte para texto estruturado.
        
        Args:
            xlsx_path: Caminho para o arquivo XLSX
            
        Returns:
            str: Conte√∫do estruturado do XLSX
        """
        try:
            # L√™ o arquivo Excel
            excel_file = pd.ExcelFile(xlsx_path)
            content = f"DADOS DO ARQUIVO EXCEL: {os.path.basename(xlsx_path)}\n\n"
            
            # Processa cada planilha
            for sheet_name in excel_file.sheet_names:
                content += f"PLANILHA: {sheet_name}\n"
                content += "=" * 50 + "\n"
                
                # L√™ os dados da planilha
                df = pd.read_excel(xlsx_path, sheet_name=sheet_name)
                
                # Adiciona informa√ß√µes sobre colunas
                content += f"COLUNAS: {', '.join(df.columns.tolist())}\n\n"
                
                # Adiciona estat√≠sticas b√°sicas
                content += f"TOTAL DE REGISTROS: {len(df)}\n\n"
                
                # Adiciona dados (limitando para n√£o ficar muito grande)
                content += "DADOS:\n"
                for index, row in df.head(50).iterrows():  # Limita a 50 linhas por planilha
                    row_text = " | ".join([f"{col}: {val}" for col, val in row.items()])
                    content += f"{row_text}\n"
                
                if len(df) > 50:
                    content += f"\n... (exibindo apenas primeiras 50 linhas de {len(df)} registros)\n"
                
                content += "\n" + "=" * 50 + "\n\n"
            
            return content
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair XLSX {xlsx_path}: {e}")
            return ""
    
    def _extract_txt_content(self, txt_path: str) -> str:
        """
        Extrai conte√∫do de um arquivo TXT.
        
        Args:
            txt_path: Caminho para o arquivo TXT
            
        Returns:
            str: Conte√∫do do arquivo TXT
        """
        try:
            # Tenta diferentes codifica√ß√µes
            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
            
            for encoding in encodings:
                try:
                    with open(txt_path, 'r', encoding=encoding) as file:
                        content = file.read()
                        
                    # Adiciona cabe√ßalho com informa√ß√µes do arquivo
                    header = f"ARQUIVO DE TEXTO: {os.path.basename(txt_path)}\n"
                    header += f"CODIFICA√á√ÉO: {encoding}\n"
                    header += "=" * 50 + "\n\n"
                    
                    return header + content.strip()
                    
                except UnicodeDecodeError:
                    continue
            
            # Se nenhuma codifica√ß√£o funcionou
            print(f"‚ö†Ô∏è  N√£o foi poss√≠vel decodificar o arquivo {txt_path}")
            return ""
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair TXT {txt_path}: {e}")
            return ""
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Retorna estat√≠sticas da base de conhecimento.
        
        Returns:
            Dict: Estat√≠sticas da base
        """
        try:
            if not self.vector_store:
                return {"error": "Vector store n√£o inicializado"}
            
            # Obt√©m estat√≠sticas do √≠ndice FAISS
            index_stats = self.db_config.get_index_stats()
            
            return {
                "vector_store_initialized": self.vector_store is not None,
                "index_stats": index_stats,
                "database_type": "FAISS"
            }
            
        except Exception as e:
            return {"error": str(e)}
    
    def clear_knowledge_base(self) -> bool:
        """
        Limpa toda a base de conhecimento.
        
        Returns:
            bool: True se limpeza foi bem-sucedida
        """
        try:
            # Reseta o √≠ndice FAISS
            if self.db_config.reset_index():
                # Reinicializa o vector store
                self._initialize_vector_store()
                print("‚úÖ Base de conhecimento limpa com sucesso!")
                return True
            return False
            
        except Exception as e:
            print(f"‚ùå Erro ao limpar base de conhecimento: {e}")
            return False


if __name__ == "__main__":
    rag_service = RAGService()
    rag_service.load_database_files_to_knowledge_base()